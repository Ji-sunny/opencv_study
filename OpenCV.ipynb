{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Download\" data-toc-modified-id=\"Download-0.0.1\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span>Download</a></span></li></ul></li></ul></li><li><span><a href=\"#Open-CV\" data-toc-modified-id=\"Open-CV-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Open CV</a></span><ul class=\"toc-item\"><li><span><a href=\"#영상처리-개요\" data-toc-modified-id=\"영상처리-개요-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>영상처리 개요</a></span></li><li><span><a href=\"#ROI\" data-toc-modified-id=\"ROI-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>ROI</a></span></li><li><span><a href=\"#히스토그램\" data-toc-modified-id=\"히스토그램-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>히스토그램</a></span><ul class=\"toc-item\"><li><span><a href=\"#2D히스토그램-으로-색조를-나타냄\" data-toc-modified-id=\"2D히스토그램-으로-색조를-나타냄-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>2D히스토그램 으로 색조를 나타냄</a></span></li></ul></li><li><span><a href=\"#Video\" data-toc-modified-id=\"Video-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Video</a></span></li><li><span><a href=\"#그리기\" data-toc-modified-id=\"그리기-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>그리기</a></span><ul class=\"toc-item\"><li><span><a href=\"#선,-사각형,-원-그리기\" data-toc-modified-id=\"선,-사각형,-원-그리기-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>선, 사각형, 원 그리기</a></span></li><li><span><a href=\"#다각형\" data-toc-modified-id=\"다각형-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>다각형</a></span></li><li><span><a href=\"#문자열-표시하기\" data-toc-modified-id=\"문자열-표시하기-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>문자열 표시하기</a></span></li></ul></li><li><span><a href=\"#이벤트-처리\" data-toc-modified-id=\"이벤트-처리-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>이벤트 처리</a></span><ul class=\"toc-item\"><li><span><a href=\"#플래그를-이용한-동그라미-그리기\" data-toc-modified-id=\"플래그를-이용한-동그라미-그리기-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>플래그를 이용한 동그라미 그리기</a></span></li><li><span><a href=\"#트백바\" data-toc-modified-id=\"트백바-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>트백바</a></span></li></ul></li><li><span><a href=\"#이미지-프로세싱\" data-toc-modified-id=\"이미지-프로세싱-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>이미지 프로세싱</a></span><ul class=\"toc-item\"><li><span><a href=\"#THRESHOLD\" data-toc-modified-id=\"THRESHOLD-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>THRESHOLD</a></span></li><li><span><a href=\"#알파-블렌딩(blending_alpha)\" data-toc-modified-id=\"알파-블렌딩(blending_alpha)-1.7.2\"><span class=\"toc-item-num\">1.7.2&nbsp;&nbsp;</span>알파 블렌딩(blending_alpha)</a></span></li><li><span><a href=\"#seamlessClone()\" data-toc-modified-id=\"seamlessClone()-1.7.3\"><span class=\"toc-item-num\">1.7.3&nbsp;&nbsp;</span>seamlessClone()</a></span></li><li><span><a href=\"#CLAHE-적용\" data-toc-modified-id=\"CLAHE-적용-1.7.4\"><span class=\"toc-item-num\">1.7.4&nbsp;&nbsp;</span>CLAHE 적용</a></span></li></ul></li><li><span><a href=\"#화질개선\" data-toc-modified-id=\"화질개선-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>화질개선</a></span><ul class=\"toc-item\"><li><span><a href=\"#모폴로지-연산-(morphologyEX)\" data-toc-modified-id=\"모폴로지-연산-(morphologyEX)-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>모폴로지 연산 (morphologyEX)</a></span></li><li><span><a href=\"#확대와-축소\" data-toc-modified-id=\"확대와-축소-1.8.2\"><span class=\"toc-item-num\">1.8.2&nbsp;&nbsp;</span>확대와 축소</a></span></li><li><span><a href=\"#어핀-변환\" data-toc-modified-id=\"어핀-변환-1.8.3\"><span class=\"toc-item-num\">1.8.3&nbsp;&nbsp;</span>어핀 변환</a></span></li><li><span><a href=\"#원근-변환\" data-toc-modified-id=\"원근-변환-1.8.4\"><span class=\"toc-item-num\">1.8.4&nbsp;&nbsp;</span>원근 변환</a></span></li><li><span><a href=\"#마우스와-원근-변환으로-문서-스캔\" data-toc-modified-id=\"마우스와-원근-변환으로-문서-스캔-1.8.5\"><span class=\"toc-item-num\">1.8.5&nbsp;&nbsp;</span>마우스와 원근 변환으로 문서 스캔</a></span></li><li><span><a href=\"#푸리에-변환\" data-toc-modified-id=\"푸리에-변환-1.8.6\"><span class=\"toc-item-num\">1.8.6&nbsp;&nbsp;</span>푸리에 변환</a></span><ul class=\"toc-item\"><li><span><a href=\"#과제\" data-toc-modified-id=\"과제-1.8.6.1\"><span class=\"toc-item-num\">1.8.6.1&nbsp;&nbsp;</span>과제</a></span></li></ul></li></ul></li><li><span><a href=\"#윤곽선-검출\" data-toc-modified-id=\"윤곽선-검출-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>윤곽선 검출</a></span><ul class=\"toc-item\"><li><span><a href=\"#합성곱(필터처리,-Convolution)\" data-toc-modified-id=\"합성곱(필터처리,-Convolution)-1.9.1\"><span class=\"toc-item-num\">1.9.1&nbsp;&nbsp;</span>합성곱(필터처리, Convolution)</a></span></li><li><span><a href=\"#바이레터럴-필터와-가우시안-필터\" data-toc-modified-id=\"바이레터럴-필터와-가우시안-필터-1.9.2\"><span class=\"toc-item-num\">1.9.2&nbsp;&nbsp;</span>바이레터럴 필터와 가우시안 필터</a></span></li><li><span><a href=\"#미디언-블러링\" data-toc-modified-id=\"미디언-블러링-1.9.3\"><span class=\"toc-item-num\">1.9.3&nbsp;&nbsp;</span>미디언 블러링</a></span></li><li><span><a href=\"#경계-검출\" data-toc-modified-id=\"경계-검출-1.9.4\"><span class=\"toc-item-num\">1.9.4&nbsp;&nbsp;</span>경계 검출</a></span><ul class=\"toc-item\"><li><span><a href=\"#윤곽선-추출-필터-(소벨-필터)\" data-toc-modified-id=\"윤곽선-추출-필터-(소벨-필터)-1.9.4.1\"><span class=\"toc-item-num\">1.9.4.1&nbsp;&nbsp;</span>윤곽선 추출 필터 (소벨 필터)</a></span></li><li><span><a href=\"#로버츠-교차-필터\" data-toc-modified-id=\"로버츠-교차-필터-1.9.4.2\"><span class=\"toc-item-num\">1.9.4.2&nbsp;&nbsp;</span>로버츠 교차 필터</a></span></li><li><span><a href=\"#샤르-필터\" data-toc-modified-id=\"샤르-필터-1.9.4.3\"><span class=\"toc-item-num\">1.9.4.3&nbsp;&nbsp;</span>샤르 필터</a></span></li><li><span><a href=\"#라플라시안-필터\" data-toc-modified-id=\"라플라시안-필터-1.9.4.4\"><span class=\"toc-item-num\">1.9.4.4&nbsp;&nbsp;</span>라플라시안 필터</a></span></li><li><span><a href=\"#캐니-엣지-알고리즘\" data-toc-modified-id=\"캐니-엣지-알고리즘-1.9.4.5\"><span class=\"toc-item-num\">1.9.4.5&nbsp;&nbsp;</span>캐니 엣지 알고리즘</a></span></li><li><span><a href=\"#케니-엣지와-카메라-(p249)\" data-toc-modified-id=\"케니-엣지와-카메라-(p249)-1.9.4.6\"><span class=\"toc-item-num\">1.9.4.6&nbsp;&nbsp;</span>케니 엣지와 카메라 (p249)</a></span></li></ul></li></ul></li><li><span><a href=\"#손글씨-숫자-인식하기\" data-toc-modified-id=\"손글씨-숫자-인식하기-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>손글씨 숫자 인식하기</a></span></li><li><span><a href=\"#6장-특징-추출\" data-toc-modified-id=\"6장-특징-추출-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>6장 특징 추출</a></span><ul class=\"toc-item\"><li><span><a href=\"#컨투어-계층-트리\" data-toc-modified-id=\"컨투어-계층-트리-1.11.1\"><span class=\"toc-item-num\">1.11.1&nbsp;&nbsp;</span>컨투어 계층 트리</a></span></li><li><span><a href=\"#모멘트를-이용한-중심점,-넓이,-둘레길이\" data-toc-modified-id=\"모멘트를-이용한-중심점,-넓이,-둘레길이-1.11.2\"><span class=\"toc-item-num\">1.11.2&nbsp;&nbsp;</span>모멘트를 이용한 중심점, 넓이, 둘레길이</a></span></li><li><span><a href=\"#컨투어를-감싸는-그림-그리기\" data-toc-modified-id=\"컨투어를-감싸는-그림-그리기-1.11.3\"><span class=\"toc-item-num\">1.11.3&nbsp;&nbsp;</span>컨투어를 감싸는 그림 그리기</a></span></li><li><span><a href=\"#근사-컨투어\" data-toc-modified-id=\"근사-컨투어-1.11.4\"><span class=\"toc-item-num\">1.11.4&nbsp;&nbsp;</span>근사 컨투어</a></span></li><li><span><a href=\"#Convex-Hull\" data-toc-modified-id=\"Convex-Hull-1.11.5\"><span class=\"toc-item-num\">1.11.5&nbsp;&nbsp;</span>Convex Hull</a></span></li></ul></li><li><span><a href=\"#캐스케이드-분류기\" data-toc-modified-id=\"캐스케이드-분류기-1.12\"><span class=\"toc-item-num\">1.12&nbsp;&nbsp;</span>캐스케이드 분류기</a></span><ul class=\"toc-item\"><li><span><a href=\"#하르-캐스케이드-얼굴-검출\" data-toc-modified-id=\"하르-캐스케이드-얼굴-검출-1.12.1\"><span class=\"toc-item-num\">1.12.1&nbsp;&nbsp;</span>하르 캐스케이드 얼굴 검출</a></span></li><li><span><a href=\"#카메라로-얼굴,-눈과-입-검출\" data-toc-modified-id=\"카메라로-얼굴,-눈과-입-검출-1.12.2\"><span class=\"toc-item-num\">1.12.2&nbsp;&nbsp;</span>카메라로 얼굴, 눈과 입 검출</a></span></li><li><span><a href=\"#얼굴-인식-모델링\" data-toc-modified-id=\"얼굴-인식-모델링-1.12.3\"><span class=\"toc-item-num\">1.12.3&nbsp;&nbsp;</span>얼굴 인식 모델링</a></span></li></ul></li><li><span><a href=\"#영상의-특징\" data-toc-modified-id=\"영상의-특징-1.13\"><span class=\"toc-item-num\">1.13&nbsp;&nbsp;</span>영상의 특징</a></span><ul class=\"toc-item\"><li><span><a href=\"#해리스-코너-검출\" data-toc-modified-id=\"해리스-코너-검출-1.13.1\"><span class=\"toc-item-num\">1.13.1&nbsp;&nbsp;</span>해리스 코너 검출</a></span></li><li><span><a href=\"#Tracker-APIs\" data-toc-modified-id=\"Tracker-APIs-1.13.2\"><span class=\"toc-item-num\">1.13.2&nbsp;&nbsp;</span>Tracker APIs</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Download\" data-toc-modified-id=\"Download-0.0.1\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span>Download</a></span></li></ul></li></ul></li><li><span><a href=\"#Open-CV\" data-toc-modified-id=\"Open-CV-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Open CV</a></span><ul class=\"toc-item\"><li><span><a href=\"#영상처리-개요\" data-toc-modified-id=\"영상처리-개요-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>영상처리 개요</a></span></li><li><span><a href=\"#ROI\" data-toc-modified-id=\"ROI-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>ROI</a></span></li><li><span><a href=\"#히스토그램\" data-toc-modified-id=\"히스토그램-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>히스토그램</a></span><ul class=\"toc-item\"><li><span><a href=\"#2D히스토그램-으로-색조를-나타냄\" data-toc-modified-id=\"2D히스토그램-으로-색조를-나타냄-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>2D히스토그램 으로 색조를 나타냄</a></span></li></ul></li><li><span><a href=\"#Video\" data-toc-modified-id=\"Video-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Video</a></span></li><li><span><a href=\"#그리기\" data-toc-modified-id=\"그리기-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>그리기</a></span><ul class=\"toc-item\"><li><span><a href=\"#선,-사각형,-원-그리기\" data-toc-modified-id=\"선,-사각형,-원-그리기-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>선, 사각형, 원 그리기</a></span></li><li><span><a href=\"#다각형\" data-toc-modified-id=\"다각형-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>다각형</a></span></li><li><span><a href=\"#문자열-표시하기\" data-toc-modified-id=\"문자열-표시하기-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>문자열 표시하기</a></span></li></ul></li><li><span><a href=\"#이벤트-처리\" data-toc-modified-id=\"이벤트-처리-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>이벤트 처리</a></span><ul class=\"toc-item\"><li><span><a href=\"#플래그를-이용한-동그라미-그리기\" data-toc-modified-id=\"플래그를-이용한-동그라미-그리기-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>플래그를 이용한 동그라미 그리기</a></span></li><li><span><a href=\"#트백바\" data-toc-modified-id=\"트백바-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>트백바</a></span></li></ul></li><li><span><a href=\"#이미지-프로세싱\" data-toc-modified-id=\"이미지-프로세싱-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>이미지 프로세싱</a></span><ul class=\"toc-item\"><li><span><a href=\"#THRESHOLD\" data-toc-modified-id=\"THRESHOLD-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>THRESHOLD</a></span></li><li><span><a href=\"#알파-블렌딩(blending_alpha)\" data-toc-modified-id=\"알파-블렌딩(blending_alpha)-1.7.2\"><span class=\"toc-item-num\">1.7.2&nbsp;&nbsp;</span>알파 블렌딩(blending_alpha)</a></span></li><li><span><a href=\"#seamlessClone()\" data-toc-modified-id=\"seamlessClone()-1.7.3\"><span class=\"toc-item-num\">1.7.3&nbsp;&nbsp;</span>seamlessClone()</a></span></li><li><span><a href=\"#CLAHE-적용\" data-toc-modified-id=\"CLAHE-적용-1.7.4\"><span class=\"toc-item-num\">1.7.4&nbsp;&nbsp;</span>CLAHE 적용</a></span></li></ul></li><li><span><a href=\"#화질개선\" data-toc-modified-id=\"화질개선-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>화질개선</a></span><ul class=\"toc-item\"><li><span><a href=\"#모폴로지-연산-(morphologyEX)\" data-toc-modified-id=\"모폴로지-연산-(morphologyEX)-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>모폴로지 연산 (morphologyEX)</a></span></li><li><span><a href=\"#어핀-변환\" data-toc-modified-id=\"어핀-변환-1.8.2\"><span class=\"toc-item-num\">1.8.2&nbsp;&nbsp;</span>어핀 변환</a></span></li><li><span><a href=\"#원근-변환\" data-toc-modified-id=\"원근-변환-1.8.3\"><span class=\"toc-item-num\">1.8.3&nbsp;&nbsp;</span>원근 변환</a></span></li><li><span><a href=\"#마우스와-원근-변환으로-문서-스캔\" data-toc-modified-id=\"마우스와-원근-변환으로-문서-스캔-1.8.4\"><span class=\"toc-item-num\">1.8.4&nbsp;&nbsp;</span>마우스와 원근 변환으로 문서 스캔</a></span><ul class=\"toc-item\"><li><span><a href=\"#과제\" data-toc-modified-id=\"과제-1.8.4.1\"><span class=\"toc-item-num\">1.8.4.1&nbsp;&nbsp;</span>과제</a></span></li></ul></li></ul></li><li><span><a href=\"#윤곽선-검출\" data-toc-modified-id=\"윤곽선-검출-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>윤곽선 검출</a></span><ul class=\"toc-item\"><li><span><a href=\"#합성곱(필터처리,-Convolution)\" data-toc-modified-id=\"합성곱(필터처리,-Convolution)-1.9.1\"><span class=\"toc-item-num\">1.9.1&nbsp;&nbsp;</span>합성곱(필터처리, Convolution)</a></span></li><li><span><a href=\"#바이레터럴-필터와-가우시안-필터\" data-toc-modified-id=\"바이레터럴-필터와-가우시안-필터-1.9.2\"><span class=\"toc-item-num\">1.9.2&nbsp;&nbsp;</span>바이레터럴 필터와 가우시안 필터</a></span></li><li><span><a href=\"#미디언-블러링\" data-toc-modified-id=\"미디언-블러링-1.9.3\"><span class=\"toc-item-num\">1.9.3&nbsp;&nbsp;</span>미디언 블러링</a></span></li><li><span><a href=\"#경계-검출\" data-toc-modified-id=\"경계-검출-1.9.4\"><span class=\"toc-item-num\">1.9.4&nbsp;&nbsp;</span>경계 검출</a></span><ul class=\"toc-item\"><li><span><a href=\"#윤곽선-추출-필터-(소벨-필터)\" data-toc-modified-id=\"윤곽선-추출-필터-(소벨-필터)-1.9.4.1\"><span class=\"toc-item-num\">1.9.4.1&nbsp;&nbsp;</span>윤곽선 추출 필터 (소벨 필터)</a></span></li><li><span><a href=\"#로버츠-교차-필터\" data-toc-modified-id=\"로버츠-교차-필터-1.9.4.2\"><span class=\"toc-item-num\">1.9.4.2&nbsp;&nbsp;</span>로버츠 교차 필터</a></span></li><li><span><a href=\"#샤르-필터\" data-toc-modified-id=\"샤르-필터-1.9.4.3\"><span class=\"toc-item-num\">1.9.4.3&nbsp;&nbsp;</span>샤르 필터</a></span></li><li><span><a href=\"#라플라시안-필터\" data-toc-modified-id=\"라플라시안-필터-1.9.4.4\"><span class=\"toc-item-num\">1.9.4.4&nbsp;&nbsp;</span>라플라시안 필터</a></span></li><li><span><a href=\"#캐니-엣지-알고리즘\" data-toc-modified-id=\"캐니-엣지-알고리즘-1.9.4.5\"><span class=\"toc-item-num\">1.9.4.5&nbsp;&nbsp;</span>캐니 엣지 알고리즘</a></span></li><li><span><a href=\"#케니-엣지와-카메라-(p249)\" data-toc-modified-id=\"케니-엣지와-카메라-(p249)-1.9.4.6\"><span class=\"toc-item-num\">1.9.4.6&nbsp;&nbsp;</span>케니 엣지와 카메라 (p249)</a></span></li></ul></li></ul></li><li><span><a href=\"#손글씨-숫자-인식하기\" data-toc-modified-id=\"손글씨-숫자-인식하기-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>손글씨 숫자 인식하기</a></span></li><li><span><a href=\"#6장-특징-추출\" data-toc-modified-id=\"6장-특징-추출-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>6장 특징 추출</a></span><ul class=\"toc-item\"><li><span><a href=\"#컨투어-계층-트리\" data-toc-modified-id=\"컨투어-계층-트리-1.11.1\"><span class=\"toc-item-num\">1.11.1&nbsp;&nbsp;</span>컨투어 계층 트리</a></span></li><li><span><a href=\"#모멘트를-이용한-중심점,-넓이,-둘레길이\" data-toc-modified-id=\"모멘트를-이용한-중심점,-넓이,-둘레길이-1.11.2\"><span class=\"toc-item-num\">1.11.2&nbsp;&nbsp;</span>모멘트를 이용한 중심점, 넓이, 둘레길이</a></span></li><li><span><a href=\"#컨투어를-감싸는-그림-그리기\" data-toc-modified-id=\"컨투어를-감싸는-그림-그리기-1.11.3\"><span class=\"toc-item-num\">1.11.3&nbsp;&nbsp;</span>컨투어를 감싸는 그림 그리기</a></span></li><li><span><a href=\"#근사-컨투어\" data-toc-modified-id=\"근사-컨투어-1.11.4\"><span class=\"toc-item-num\">1.11.4&nbsp;&nbsp;</span>근사 컨투어</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convex-Hull\" data-toc-modified-id=\"Convex-Hull-1.11.4.1\"><span class=\"toc-item-num\">1.11.4.1&nbsp;&nbsp;</span>Convex Hull</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download\n",
    "\n",
    "다운로드\n",
    "pip install openCV-python\n",
    "pip install opencv-contrib-python  (다른 모듈도 같이 포함되어 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "fname = 'lena.jpg'\n",
    "original = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "cv2.imshow('Original', original)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # numpy 배열로 반환 3 의 뜻은 3차원 배열로 color \n",
    "print(type(original), original.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img =cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "b, g, r = cv2.split(img)  #오픈 CV의 채널 순서 :BGR\n",
    "img2 = cv2.merge([r, g, b]) #numpy는 이미지를 RGB순으로 채널을 읽음\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pip install jupyter_contrib_nbextensions && jupyter contrib nbextension install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open CV\n",
    "## 영상처리 개요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('lena.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "height, width, channel = img.shape  #컬러의 경우\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        if(y%2 ==0):\n",
    "            img[y,x] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def black_lines(img):\n",
    "    height, width = img.shape\n",
    "    img_ = np.zeros(img.shape, dtype = np.uint8)\n",
    "    for y in range(height):\n",
    "        if(y%2 ==0):\n",
    "            img_[y, :] =0\n",
    "        else:\n",
    "            img_[y, :] = img[y, :]\n",
    "    return img_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def img_pro(func, img, *args, show=True, **kwargs):\n",
    "    img_= func(img, *args, **kwargs)\n",
    "    if show:\n",
    "        cv2.imshow(\"output\", img_)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        return img_\n",
    "\n",
    "def img_show(img, *args, show=True, **kwargs):\n",
    "    if show:\n",
    "        cv2.imshow(\"output\", img)\n",
    "        cv2.waitKey() #1밀리초안에 key값이 들어가야함 넘어가면 -1\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"lena.jpg\", flags = cv2.IMREAD_GRAYSCALE)\n",
    "img_pro(black_lines, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('./images/lena.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp = img[200:380, 200:360]\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('roi_img', temp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "b, g, r = cv2.split(img)\n",
    "np.mean(b), np.mean(g), np.mean(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img[:, :, [1,2]] = 0  # red링 green 0으로 \n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_blending(img1, img2, img1_weight=0.5):\n",
    "    output = np.zeros(img1.shape, dtype = np.uint8)\n",
    "    height, width = img1.shape[0 :2]\n",
    "    if len(img1.shape) ==2:\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                output[x, y] = int(img1[y,x]* img1_weight + img2[y, x]* (1-img1_weight))\n",
    "    elif len(img1.shape) ==3:\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                blended = int(img1[y,x]* img1_weight + img2[y, x]* (1-img1_weight))\n",
    "                output[y, x] = blended.astype(np.uint8)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ez_blending(img1, img2, img1_weight=0.5):\n",
    "    output = img1 * img1_weight + img2*(1-img1_weight)\n",
    "    return output.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img1 = cv2.imread('./images/flower1.jpg')\n",
    "img2 = cv2.imread('./images/flower2.jpg')\n",
    "new_img = ez_blending(img1, img2, img1_weight= 0.3)\n",
    "img_show(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./images/logo.png')\n",
    "img2 = cv2.imread('./images/flower2.jpg')\n",
    "\n",
    "rows, cols, channels = img1.shape\n",
    "roi = img2[0:rows, 0:cols]  #대상에서 삽입할 이미지의 영역을 추출\n",
    "\n",
    "#mask로 만들기 위해서 img1을 gray로 변경후 binary image로 전환\n",
    "#mask는 로고가 흰색(255), 배경이 검은색 (0)\n",
    "#mask_inv 는 mask의 반대\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(img1_gray, 100,255, cv2.THRESH_BINARY)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "#and연산은 둘다 0이 아닌 경우만 통과시키며, mask에서 검정이 아닌 부분 로고부분이 나옴\n",
    "\n",
    "img_fg = cv2.bitwise_and(img1, img1, mask=mask)\n",
    "img2_bg = cv2.bitwise_and(roi, roi, mask= mask_inv)\n",
    "dst = cv2.add(img_fg, img2_bg)\n",
    "\n",
    "img2[0:rows, 0:cols] = dst\n",
    "\n",
    "img_show(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./images/logo.png')\n",
    "img2 = cv2.imread('./images/flower2.jpg')\n",
    "\n",
    "mask = np.full_like(img1, 255)\n",
    "h, w = img2.shape[:2]\n",
    "center = (w//2, h//2)\n",
    "normal = cv2.seamlessClone(img1, img2, mask, center, cv2.NORMAL_CLONE) #모자이크\n",
    "mixed  = cv2.seamlessClone(img1, img2, mask, center, cv2.MIXED_CLONE)  #투명\n",
    "\n",
    "img_show(normal)\n",
    "img_show(mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# True는 1, False 0\n",
    "def two_tone(img, threshold= 128):\n",
    "    output = (img > threshold) * 255\n",
    "    return output.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img2 = cv2.imread('./images/flower2.jpg', 0)\n",
    "new_img = two_tone(img2)\n",
    "img_show(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hou = cv2.imread('./images/house-full.jpg', 0)\n",
    "ret, th1= cv2.threshold(hou, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "th2 = cv2.adaptiveThreshold(hou, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "th3 = cv2.adaptiveThreshold(hou, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 2)\n",
    "\n",
    "title = ['original', 'global', 'mean', 'gaussian']\n",
    "\n",
    "images=[hou, th1, th2, th3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(title[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 히스토그램\n",
    " - 이미지의 농도 분포\n",
    " - 콘트라스트 강조 (골고루 분포되도록 함) >> normalize\n",
    " - 히스토그램 평활화 (우상향 그래프가 만들어짐 전체적으로골고루 분포) 하지만 이미지가 전체적으로 어두울때 밝은 부분이 너무 밝아지는 단점)\n",
    " - CLAHE (특정화소가 너무 높으면 다른 화소로 보냄)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./images/couple2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "hist = np.zeros((256))\n",
    "h, w = img.shape\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        hist[img[y,x]] = hist[img[y,x]] +1\n",
    "        \n",
    "plt.bar(x=range(256), height=hist, width =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lena_gray = cv2.imread(\"./images/lena.jpg\", 1)\n",
    "hist = cv2.calcHist(images=[lena_gray], channels=[0], mask=None, \n",
    "                   histSize=[256], ranges=[0,256])\n",
    "plt.plot(hist.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lena =cv2.imread('./images/lena.jpg')\n",
    "hist = cv2.calcHist(images=[lena], channels=[2], mask=None, \n",
    "                   histSize=[256], ranges=[0, 256])\n",
    "plt.plot(hist.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D히스토그램 으로 색조를 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/home.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "hist = cv2.calcHist([hsv], [0,1], None, [180, 256], [0, 180, 0, 256])\n",
    "\n",
    "#print(hist.shape)  #180, 256\n",
    "\n",
    "plt.imshow(hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(hist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('./images/lena.jpg')\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#영상의 점 1개는 1바이트\n",
    "#grayscale은 0부터 255(포함)까지 단계로 색(회색조)를 표현\n",
    "#컬러영상 - RGB 표현, HSV 표현, alpha(불투명도)값으로 투명도를 조절함\n",
    "\n",
    "#이미지형식: jpg, png, gif, bmp, tiff\n",
    "#00000010 00000001 00000011 -> 061101 0711 0612(0이 6개 1이 2개)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_show(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv2.imwrite('lena_gray.jpg', gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(\"puppy.mp4\") # 노트불의 경우 0번째는 노트북의 카메라 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if cap.isOpened():\n",
    "    delay = int(1000/cap.get(cv2.CAP_PROP_FPS)) #1초: 1000/ 초당 프레임수\n",
    "    while True:\n",
    "        ret, img = cap.read() # 프레임을 한장씩 가져옴 ret는 있으면 True \n",
    "        if ret:\n",
    "            cv2.imshow(\"Puppy\", img)\n",
    "            if cv2.waitKey(delay) & 0xFF ==27: #esc누르면 꺼짐\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    print(\"비디오 안열림\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if cap.isOpened():\n",
    "    delay = int(1000/cap.get(cv2.CAP_PROP_FPS)) #1초: 1000/ 초당 프레임수 숫자가 작을수록 빨라짐\n",
    "    while True:\n",
    "        ret, img = cap.read() # 프레임을 한장씩 가져옴 ret는 있으면 True \n",
    "        if ret:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            cv2.imshow(\"Puppy\", gray)\n",
    "            if cv2.waitKey(delay) & 0xFF ==27: #esc누르면 꺼짐\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    print(\"비디오 안열림\")\n",
    "cap.release() #release를 해야 비디오가 나옴\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX') #DIVX, XVID, FMP4, X264, MJPG\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "size = (int(width), int(height))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "out = cv2.VideoWriter(\"video.avi\", fourcc, fps, size)\n",
    "if cap.isOpened():\n",
    "    delay = int(1000/cap.get(cv2.CAP_PROP_FPS)) #1초: 1000/ 초당 프레임수 숫자가 작을수록 빨라짐\n",
    "    while True:\n",
    "        ret, img = cap.read() # 프레임을 한장씩 가져옴 ret는 있으면 True \n",
    "        if ret:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            cv2.imshow(\"Puppy\", gray)\n",
    "            if cv2.waitKey(delay) & 0xFF ==27: #esc누르면 꺼짐\n",
    "                print(\"윈도우 종료\")\n",
    "                break\n",
    "        else:\n",
    "            print(ret, img)\n",
    "            break\n",
    "else:\n",
    "    print(\"비디오 안열림\")\n",
    "out.release()\n",
    "cap.release() #release를 해야 비디오가 나옴\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선, 사각형, 원 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cv2.line(img, start, end, color, thickness=1)\n",
    "#cv2.rectangle(img, start, end, color, thickness=1)\n",
    "# thickness = -1이면 색이 채워진다.\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img  = np.full((250, 250, 3), 255, dtype=np.uint8)\n",
    "\n",
    "cv2.line(img, (50, 10), (200, 10), (255, 0, 0), 1)\n",
    "cv2.line(img, (50, 60), (200, 60), (255, 256, 0), 2)\n",
    "cv2.line(img, (50, 110), (200, 110), (255, 0, 255), 3)\n",
    "cv2.line(img, (50, 160), (200, 160), (0, 0, 255), 4)\n",
    "\n",
    "cv2.imshow('Lines', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img  = np.full((250, 250, 3), 255, dtype=np.uint8)\n",
    "\n",
    "cv2.rectangle(img, (50, 10), (200, 50), (255, 0, 0), 1)\n",
    "cv2.rectangle(img, (50, 60), (200, 100), (255, 256, 0), 5)\n",
    "cv2.rectangle(img, (50, 110), (200, 150), (255, 0, 255), -1)\n",
    "cv2.rectangle(img, (50, 160), (200, 200), (0, 0, 255), 5)\n",
    "cv2.rectangle(img, (50, 160), (200, 200), (0, 255, 255), -1)\n",
    "\n",
    "cv2.imshow('Rectangle', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cv2.circle(img, center, redius, color, thickness=1)\n",
    "\n",
    "img = np.full((250, 250, 3), 255, dtype=np.uint8)\n",
    "\n",
    "cv2.circle(img, (50, 50), 20, (255, 0, 0))\n",
    "cv2.circle(img, (150, 50), 50, (255, 255, 0), -1)\n",
    "cv2.circle(img, (200, 150), 30, (0, 0, 0), -1)\n",
    "cv2.circle(img, (150, 50), 100, (255, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('Circle', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cv2.ellipse(img, center, axes, angle, startAngle, endAngle, color, thickness=1)\n",
    "\n",
    "img = np.full((250, 250, 3), 255, dtype=np.uint8)\n",
    "\n",
    "cv2.ellipse(img, (50, 50),(50,30), -30, 0, 360, (255, 0, 0))\n",
    "cv2.circle(img, (150, 50), 50, (255, 255, 0), -1)\n",
    "cv2.circle(img, (200, 150), 30, (0, 0, 0), -1)\n",
    "cv2.circle(img, (150, 50), 100, (255, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('Ellipse', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다각형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cv2.polylines(img, points, isClosed, color, thickness)\n",
    "\n",
    "img = np.full((250, 250, 3), 25, dtype=np.uint8)\n",
    "points = np.array([[[60, 60], [100, 10], [200, 60], [150, 100], [100, 100]]], dtype=np.int32)\n",
    "\n",
    "cv2.polylines(img, points, True, (255, 0, 0), 5)\n",
    "cv2.polylines(img, points+[0, 100], False, (0, 0, 255), 10)\n",
    "\n",
    "cv2.imshow('Polylines', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문자열 표시하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cv2.putText(img, text, org, font, fontscale, color)\n",
    "# org = 글자의 왼쪽 아래의 좌표\n",
    "\n",
    "img = np.full((250, 250, 3), 255, dtype=np.uint8)\n",
    "\n",
    "cv2.putText(img, \"HELLO\", (10, 50), cv2.FONT_ITALIC, 1, (255,0,0))\n",
    "cv2.putText(img, \"Python\", (50, 150), cv2.FONT_ITALIC, 1, (255,0,0))\n",
    "\n",
    "cv2.imshow('Txt', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이벤트 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 플래그를 이용한 동그라미 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "title = 'mouse event'\n",
    "img = cv2.imread('./images/hand.png')\n",
    "cv2.imshow(title, img)\n",
    "\n",
    "colors = {'black': (0, 0, 0),\n",
    "        'red': (0, 0, 255),\n",
    "        'green': (0, 255, 0),\n",
    "        'blue': (255, 0, 0)}\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    print(event, x, y, flags)\n",
    "    color = colors['black']\n",
    "    if event == cv2.EVENT_FLAG_LBUTTON:\n",
    "        #컨트롤키와 시프트키를 모두 누른 경우\n",
    "        if flags & cv2.EVENT_FLAG_SHIFTKEY and flags & cv2.EVENT_FLAG_CTRLKEY:\n",
    "            color = colors['green']\n",
    "        elif flags & cv2.EVENT_FLAG_SHIFTKEY: \n",
    "            color = colors['blue']\n",
    "        elif flags & cv2.EVENT_FLAG_CTRLKEY:\n",
    "            color = colors['red']\n",
    "        cv2.circle(img, (x,y), 30, color, -1)\n",
    "        cv2.imshow(title, img)\n",
    "cv2.setMouseCallback(title, onMouse)  #마우스 콜백 함수를 GUI 윈도에 등록\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(-1) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트백바"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "win_name = 'Trackbar'\n",
    "\n",
    "img  = np.full((500, 500, 3), 255, dtype=np.uint8)\n",
    "cv2.imshow(win_name, img)\n",
    "\n",
    "def onChange(x):\n",
    "    print(x)\n",
    "    # R G B 의 트백바 위치값\n",
    "    r = cv2.getTrackbarPos('R', win_name)\n",
    "    g = cv2.getTrackbarPos('G', win_name)\n",
    "    b = cv2.getTrackbarPos('B', win_name)\n",
    "    \n",
    "    print(r, g, b)\n",
    "    img[:] = [b, g, r]\n",
    "    cv2.imshow(win_name, img)\n",
    "    \n",
    "#트랙바 생성\n",
    "cv2.createTrackbar('R', win_name, 255, 255, onChange)\n",
    "cv2.createTrackbar('G', win_name, 255, 255, onChange)\n",
    "cv2.createTrackbar('B', win_name, 255, 255, onChange)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(-1) & 0xFF ==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#141, 137, 130, 126\n",
    "## 이미지 프로세싱 \n",
    "### THRESHOLD\n",
    " - 이미지를 여러 영역으로 나눈 다음에 그 주변 픽셀 값만 가지고 계싼을 해서 경계 값을 구하는 방법 (적응형 스레시 홀드)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "img = cv2.imread('./images/gradient.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "_, t_bin = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "_, t_bininv = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "_, t_truc = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)\n",
    "_, t_2zr = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)\n",
    "_, t_2zrinv = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "\n",
    "imgs = {'original': img, 'BINARY': t_bin, 'BINART_INV': t_bininv, 'TRUNC':t_truc, 'TOZERO':t_2zr, 'TOZEROINV': t_2zrinv}\n",
    "\n",
    "for i, (key, value) in enumerate(imgs.items()):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.title(key)\n",
    "    plt.imshow(value, cmap='gray')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/dave.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "blk_size=9 #블록 사이즈\n",
    "C=5 # 차감상수\n",
    "\n",
    "#오츠의 알고리즘으로 단일 경계값을 전체 이미지에 적용\n",
    "ret, th1 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "# 적응형 스레시 홀드를 평균과 가우시안 분포로 각각 적용\n",
    "\n",
    "th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blk_size, C)\n",
    "th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blk_size, C)\n",
    "\n",
    "imgs = {'Original': img, 'Global-Otsu:%d'%ret:th1, 'Adapted-Mean':th2, 'Adapted-Gaussian':th3}\n",
    "for i, (k,v) in enumerate(imgs.items()):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.title(k)\n",
    "    plt.imshow(v, cmap='gray')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 알파 블렌딩(blending_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "alpha = 0.8\n",
    "\n",
    "#합성에 사용할 영상\n",
    "img1 = cv2.imread('./images/tes.jpg')\n",
    "img1 = cv2.resize(img1, (500, 500))\n",
    "img2 = cv2.imread('./images/flowerback.jpg')\n",
    "img2 = cv2.resize(img2, (500, 500))\n",
    "\n",
    "#수식을 직접 연산해서 알파 블렌딩 적용\n",
    "blended = img1*alpha + img2*(1-alpha)\n",
    "blended = blended.astype(np.uint8)  #소수점 제거\n",
    "cv2.imshow('img1*alpha + img2*(1-alpha)', blended)\n",
    "\n",
    "#addWeighted() 함수로 알파 블렌딩 적용\n",
    "dst = cv2.addWeighted(img1, alpha, img2, (1-alpha), 0)\n",
    "cv2.imshow('addWeighted', dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, cv2\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "img = cv2.imread('./images/hip.png')\n",
    "img = cv2.resize(img, (500, 500))\n",
    "\n",
    "mask = np.zeros_like(img)\n",
    "cv2.circle(mask, (250, 100), 200, (255, 255, 255), -1)\n",
    "#cv2.circle(대상 이미지, (원점x, 원점y), 반지름, (색상), 채우기)\n",
    "\n",
    "#마스킹\n",
    "masked = cv2.bitwise_and(img, mask)\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('masked', masked)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seamlessClone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread('./images/plane.jpg') #w전경\n",
    "dst = cv2.imread('./images/back.jpg') # 배경\n",
    "h, w = dst.shape[:2]\n",
    "\n",
    "src_mask = np.zeros(src.shape, src.dtype)\n",
    "poly = np.array([[0, 40], [150, 60], [203, 56], [200, 100], [88, 103], [1, 75]], np.int32)\n",
    "\n",
    "\n",
    "cv2.fillPoly(src_mask, [poly], (255,255,255))\n",
    "\n",
    "center = (500, 100)\n",
    "output = cv2.seamlessClone(src, dst, src_mask, center, cv2.MIXED_CLONE)\n",
    "\n",
    "cv2.imshow('output', output)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "img = cv2.imread('./images/sunset.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "rows, cols = img.shape[:2]\n",
    "hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "cdf = hist.cumsum()\n",
    "cdf_m = np.ma.masked_equal(cdf, 0)\n",
    "cdf_m = (cdf_m - cdf_m.min())/ (rows * cols) *255 # 이퀄라이즈 히스토그램 계산 \n",
    "cdf = np.ma.filled(cdf_m, 0).astype('uint8') #NaN을 0으로\n",
    "img2 = cdf[img] # 히스토그램 픽셀로 매핑\n",
    "\n",
    "#openCV API로 이퀄라이즈 히스토그램 적용\n",
    "img3 = cv2.equalizeHist(img)\n",
    "\n",
    "hist2=cv2.calcHist([img2], [0], None, [256], [0, 256])\n",
    "hist3=cv2.calcHist([img3], [0], None, [256], [0, 256])\n",
    "\n",
    "cv2.imshow('Before', img)\n",
    "cv2.imshow('Manual', img2)\n",
    "cv2.imshow('equalize', img3)\n",
    "\n",
    "hists= {'Befoer': hist, 'Manual': hist2, 'equalize': hist3}\n",
    "for i, (k,v) in enumerate(hists.items()):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.title(k)\n",
    "    plt.plot(v)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLAHE 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/butterfly.jpg')\n",
    "img_yu = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "#밝기 채널에 대해서 이퀄라이즈 적용\n",
    "img_eq = img_yu.copy()\n",
    "img_eq[:,:,0] = cv2.equalizeHist(img_eq[:,:,0])\n",
    "img_eq = cv2.cvtColor(img_eq, cv2.COLOR_YUV2RGB)\n",
    "\n",
    "#밝기 채널에 대해서 CLAHE 적용\n",
    "img_clahe = img_yu.copy()\n",
    "clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize=(8,8))\n",
    "img_clahe[:, :, 0] = clahe.apply(img_clahe[:,:,0])\n",
    "img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "#결과 출력 \n",
    "cv2.imshow('Before', img)\n",
    "cv2.imshow('CLAHE', img_clahe)\n",
    "cv2.imshow('equalizeHist', img_eq)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 화질개선\n",
    "\n",
    "### 모폴로지 연산 (morphologyEX)\n",
    "- 침식(erode)\n",
    "- 팽창(dilate)\n",
    "- 열기(opening)\n",
    "- 닫기(closing)\n",
    "1. 수축: 화소의 부그에 하나라도 0이면 그 화소를 0으로 처리 그외는 255\n",
    "2. 팽창: 화소의 부근에 하나라도 255이면 그화소를 255로 처리 그외는 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def contraction (img_in):\n",
    "    height, width = img_in.shape\n",
    "    img_out = np.zeros(img_in.shape, np.uint8)\n",
    "    for y in range(1, height-1):\n",
    "        for x in range(1, width-1):\n",
    "            img_out[y,x] = img_in[y, x]\n",
    "            if img_in[y-1, x-1] ==0:\n",
    "                img_out[y,x] = 0\n",
    "            if img_in[y-1, x] ==0:\n",
    "                img_out[y,x] = 0\n",
    "            if img_in[y-1, x+1] ==0:\n",
    "                img_out[y,x] = 0\n",
    "                \n",
    "            if img_in[y, x-1] ==0:\n",
    "                img_out[y,x] = 0\n",
    "            if img_in[y, x+1] ==0:\n",
    "                img_out[y,x] = 0\n",
    "            if img_in[y+1, x-1] ==0:\n",
    "                img_out[y,x] = 0\n",
    "            if img_in[y+1, x] ==0:\n",
    "                img_out[y,x] = 0\n",
    "            if img_in[y+1, x+1] ==0:\n",
    "                img_out[y,x] = 0\n",
    "    return img_out\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/mor.png', cv2.IMREAD_GRAYSCALE)\n",
    "img5_cont = contraction(img)\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow(\"cons\", img5_cont)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/mor.png', cv2.IMREAD_GRAYSCALE)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "cv2.imshow('j', img)\n",
    "cv2.imshow('dilate', cv2.dilate(img, kernel, iterations=1))\n",
    "cv2.imshow('mor', cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 확대와 축소\n",
    " - 침색, 팽창, 열기, 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/hip.png')\n",
    "img = cv2.resize(img, (500, 500))\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "dst1 = cv2.resize(img, (int(w*0.5), int(h*0.5)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# 배율 지정으로 확대\n",
    "\n",
    "dst2 = cv2.resize(img, None, None, 2, 2, cv2.INTER_CUBIC)\n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"small\", dst1)\n",
    "cv2.imshow(\"big\", dst2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어핀 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "fname = './images/hip.png'\n",
    "img = cv2.imread(fname)\n",
    "img = cv2.resize(img, (500,500))\n",
    "\n",
    "pts1 = np.float32([[100,50], [200, 50], [100, 200]])\n",
    "pts2 = np.float32([[80, 70], [210, 60], [250, 120]])\n",
    "\n",
    "#변환전 좌표 표시\n",
    "cv2.circle(img, (100, 50), 5, (255, 0), -1)\n",
    "cv2.circle(img, (200, 50), 5, (0, 255, 0), -1)\n",
    "cv2.circle(img, (100, 200), 5, (0, 0, 255), -1)\n",
    "\n",
    "#짝지은 3개의 좌표로 변환행렬 계싼\n",
    "mtrx = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "#어핀 변환 적용\n",
    "dst = cv2.warpAffine(img, mtrx, (int(cols*1.5), rows))\n",
    "\n",
    "\n",
    "#결과 출력\n",
    "cv2.imshow('origin', img)\n",
    "cv2.imshow('affin', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원근 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fname = './images/hip.png'\n",
    "img = cv2.imread(fname)\n",
    "img = cv2.resize(img, (500, 500))\n",
    "\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "pts1 = np.float32([[0,0], [0, rows], [cols,0], [cols, rows]])\n",
    "pts2 = np.float32([[100, 50], [10, rows-50], [cols-100, 50], [cols-10, rows-50]])\n",
    "\n",
    "#변환전 원본 이미지에 좌표 포시\n",
    "cv2.circle(img, (0, rows), 5, (255, 0), -1)\n",
    "cv2.circle(img, (cols, 0), 5, (0, 255, 0), -1)\n",
    "cv2.circle(img, (0, 0), 5, (0, 0, 255), -1)\n",
    "cv2.circle(img, (cols, rows), 5, (0, 255, 255), -1)\n",
    "\n",
    "#원근 변환행렬 계산\n",
    "mtrx = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "#원근 변환 적용\n",
    "dst = cv2.warpPerspective(img, mtrx, (cols, rows))\n",
    "\n",
    "cv2.imshow('origin', img)\n",
    "cv2.imshow('perspective', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마우스와 원근 변환으로 문서 스캔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fname = './images/hip.png'\n",
    "win_name = 'scanning'\n",
    "img = cv2.imread(fname)\n",
    "img = cv2.resize(img, (500, 740))\n",
    "\n",
    "rows, cols = img.shape[:2]\n",
    "draw = img.copy()\n",
    "pts_cnt = 0\n",
    "pts = np.zeros((4,2), dtype=np.float32)\n",
    "\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    global pts_cnt\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(draw, (x,y), 10, (0, 255, 0), -1)\n",
    "        cv2.imshow(win_name, draw)\n",
    "        pts[pts_cnt] = [x,y]\n",
    "        pts_cnt +=1\n",
    "        if pts_cnt ==4:\n",
    "            #좌표 4개 중 상하좌우 찾기\n",
    "            sm = pts.sum(axis=1)\n",
    "            diff = np.diff(pts, axis = 1)\n",
    "            topleft = pts[np.argmin(sm)]\n",
    "            bottom = pts[np.argmax(sm)]\n",
    "            topright = pts[np.argmin(diff)]\n",
    "            bottomLeft = pts[np.argmax(diff)]\n",
    "            \n",
    "            pts1 = np.float32([topleft, topright, bottom, bottomLeft])\n",
    "            \n",
    "            w1 = abs(bottom[0]-bottomLeft[0])\n",
    "            w2 = abs(topright[0]-topleft[0])\n",
    "            h1 = abs(topright[1]-bottom[1])\n",
    "            h2 = abs(topleft[1]- bottomLeft[1])\n",
    "            \n",
    "            width = max([w1, w2])\n",
    "            height = max([h1, h2])\n",
    "            \n",
    "            pts2 = np.float32([[0,0], [width-1, 0], [width-1, height-1], [0, height-1] ])\n",
    "            \n",
    "            mtrx = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "            result = cv2.warpPerspective(img, mtrx, (width, height))\n",
    "            cv2.imshow('scann', result)\n",
    "            \n",
    "cv2.imshow(win_name, img)\n",
    "cv2.setMouseCallback(win_name, onMouse)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 푸리에 변환\n",
    "- 고주파는 경계선을 의미하고, 저주파는 배경을 의미함\n",
    "- ffishift() 는 제로 주파수 성분을 스펙트럼의 중심으로 이동 (넘파이 배열)\n",
    "- dft() (open CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T01:42:04.857200Z",
     "start_time": "2021-04-26T01:42:04.660321Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"./images/lena.jpg\", 0)\n",
    "dft = cv2.dft(np.float32(img), flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "\n",
    "dft_shift = np.fft.fftshift(dft) #이미지에 푸리에 변환 적용\n",
    "dft_magni = cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]) \n",
    "magnitude_spectrum = 20*np.log(dft_magni) # spectrum을 구하는 수학식\n",
    "\n",
    "rows, cols = img.shape\n",
    "crow, ccol = int(rows/2), int(cols/2)\n",
    "\n",
    "#d는 20x20의 사각형을 생성한 후 사각형의 바깥쪽을 제거하는 형태이며 고주파 영역을 제거함\n",
    "#d의 값이 작을 수록 고주파가 더 많이 삭제되며서 이미지가 뭉게짐\n",
    "d = 30\n",
    "\n",
    "#윤곽선 뭉개기\n",
    "# mask = np.zeros((rows, cols, 2), np.uint8)\n",
    "# mask[crow-d: crow+d, ccol-d:ccol+d] =1\n",
    "\n",
    "#윤곽선 찾기\n",
    "mask = np.ones((rows, cols, 2), np.uint8)\n",
    "mask[crow-d: crow+d, ccol-d:ccol+d] =0\n",
    "\n",
    "#푸리에 변환 결과를 다시 이미지로 변환\n",
    "fshift = dft_shift*mask\n",
    "f_ishift = np.fft.ifftshift(fshift)\n",
    "img_back = cv2.idft(f_ishift)\n",
    "img_back = cv2.magnitude(img_back[:,:,0], img_back[:, :,1])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('Input Image')\n",
    "plt.xticks([]); plt.yticks([])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_back, cmap='gray')\n",
    "plt.title('FT')\n",
    "plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-26T02:30:21.581Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "pts_cnt = 0\n",
    "pts = np.zeros((4,2), dtype=np.float32)\n",
    "\n",
    "def mouseHandler(event, x, y, flags, param):\n",
    "    global pts_cnt\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img, (x,y), 10, (0, 255, 0), -1)\n",
    "        cv2.imshow( 'scanning', img)\n",
    "        pts[pts_cnt] = [x,y]\n",
    "        pts_cnt +=1\n",
    "        if pts_cnt ==4:\n",
    "            #좌표 4개 중 상하좌우 찾기\n",
    "            sm = pts.sum(axis=1)\n",
    "            diff = np.diff(pts, axis = 1)\n",
    "            topleft = pts[np.argmin(sm)]\n",
    "            bottom = pts[np.argmax(sm)]\n",
    "            topright = pts[np.argmin(diff)]\n",
    "            bottomLeft = pts[np.argmax(diff)]\n",
    "            \n",
    "            pts1 = np.float32([topleft, topright, bottom, bottomLeft])\n",
    "            \n",
    "            w1 = abs(bottom[0]-bottomLeft[0])\n",
    "            w2 = abs(topright[0]-topleft[0])\n",
    "            h1 = abs(topright[1]-bottom[1])\n",
    "            h2 = abs(topleft[1]- bottomLeft[1])\n",
    "            \n",
    "            width = max([w1, w2])\n",
    "            height = max([h1, h2])\n",
    "            \n",
    "            pts2 = np.float32([[0,0], [width-1, 0], [width-1, height-1], [0, height-1] ])\n",
    "            \n",
    "            mtrx = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "            result = cv2.warpPerspective(img, mtrx, (width, height))\n",
    "            cv2.imshow('scann', result)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "captured = False\n",
    "\n",
    "if cap.isOpened():\n",
    "    delay = int(1000/cap.get(cv2.CAP_PROP_FPS)) \n",
    "    while True:\n",
    "        ret, img = cap.read() \n",
    "        if ret:\n",
    "            cv2.imshow(\"Capture\", img)\n",
    "            key = cv2.waitKey(delay)\n",
    "            if key & 0xFF ==27:\n",
    "                print(\"아무 작업도 하지 않고 종료함\")\n",
    "                break\n",
    "            elif key == ord('c'):\n",
    "                captured = True\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    print(\"비디오 안열림\")\n",
    "    \n",
    "if captured:\n",
    "    cap.release()\n",
    "    while True:\n",
    "        cv2.imshow('Capture', img)\n",
    "        cv2.setMouseCallback('Capture', mouseHandler)\n",
    "        key = cv2.waitKey(delay)\n",
    "        if key & 0xFF ==27:\n",
    "            print(\"ESC\")\n",
    "            break\n",
    "\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 윤곽선 검출\n",
    "### 합성곱(필터처리, Convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:42:56.156613Z",
     "start_time": "2021-04-23T12:42:56.150130Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Conv2D(img, mask=None, padding='valid'):\n",
    "    if mask is not None:\n",
    "        sy, sx = int(len(mask)/2), int(len(mask[0])/2)\n",
    "        if padding ==\"same\":\n",
    "            new_shape = img.shape[:2] + (sy, sx)\n",
    "            img_out = np.zeros(new_shape, dtype=np.uint8)\n",
    "        elif padding =='valid':\n",
    "            img_out = np.zeros(img.shape, dtype=np.uint8)\n",
    "            \n",
    "        height, width = img_out.shape[:2]\n",
    "        for y in range(sy, height-sy):\n",
    "            for x in range(sx, width-sx):\n",
    "                roi = img[y-sy: y+sy+1, x-sx: x+sx+1]\n",
    "                filtered = roi * mask\n",
    "                img_out[y, x] = np.uint8(np.abs(np.sum(filtered)))\n",
    "        return img_out[sy: -sy, sx: -sx]\n",
    "    else:\n",
    "        print(\"Mask array not found\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:43:14.990497Z",
     "start_time": "2021-04-23T12:43:05.028680Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('./images/lena.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "mask = np.array([[0,0,-1],[-1,2,-1],[0,-1,0]])\n",
    "print(mask)\n",
    "con = Conv2D(img, mask=mask)\n",
    "cv2.imshow('Conv2D', con)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바이레터럴 필터와 가우시안 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:43:50.763710Z",
     "start_time": "2021-04-23T12:43:18.960136Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/lena.jpg')\n",
    "\n",
    "#가우시안 필터\n",
    "blur1 = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "#바이레터럴 필터\n",
    "blur2 = cv2.bilateralFilter(img, 5, 75,75)\n",
    "\n",
    "merged= np.hstack((img, blur1, blur2))\n",
    "cv2.imshow('bilateral', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미디언 블러링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:43:58.551900Z",
     "start_time": "2021-04-23T12:43:54.161013Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./images/lena.jpg')\n",
    "\n",
    "blur = cv2.medianBlur(img, 7)\n",
    "blur2 = cv2.medianBlur(img,3)\n",
    "\n",
    "merged =np.hstack((img, blur, blur2))\n",
    "cv2.imshow('media', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경계 검출\n",
    "\n",
    " - 엣지(edge)를 검출하는 것은 배경과 전경을 분리하는 데 가장 기본\n",
    " - 차분 필터: 차이를 계산해줌\n",
    " - 로버츠 필터\n",
    " - 프리위트 필터: 미분 필터\n",
    " - 소벨 필터\n",
    " - 샤르필터\n",
    " - 라플라시안 필터(라플라시안1, 라플라시안2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:44:20.025907Z",
     "start_time": "2021-04-23T12:44:13.207261Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"./images/lena.jpg\")\n",
    "\n",
    "#미분 커널 생성 ---①\n",
    "gx_kernel = np.array([[ -1, 1]])\n",
    "gy_kernel = np.array([[ -1],[ 1]])\n",
    "\n",
    "# 필터 적용 ---②\n",
    "edge_gx = cv2.filter2D(img, -1, gx_kernel)\n",
    "edge_gy = cv2.filter2D(img, -1, gy_kernel)\n",
    "# 결과 출력\n",
    "merged = np.hstack((img, edge_gx, edge_gy))\n",
    "# merged = np.c_[img, edge_gx, edge_gy]\n",
    "cv2.imshow('edge', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 윤곽선 추출 필터 (소벨 필터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:44:26.940448Z",
     "start_time": "2021-04-23T12:44:26.934078Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sovel_filter(img):\n",
    "    img_ = np.zeros(img.shape, dtype = np.uint8)\n",
    "    height, width = img.shape[:2]\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            try: \n",
    "                H = 1*img[y-1, x-1] + -1*img[y-1, x+1] \\\n",
    "                + 2* img[y, x-1] + -2*img[y, x+1]\\\n",
    "                + 1* img[y+1, x-1] + -1*img[y+1, x+1]\n",
    "                \n",
    "                V = 1*img[y-1, x-1] + 2*img[y-1, x] \\\n",
    "                +1*img[y-1, x+1] + -1*img[y+1, x-1]\\\n",
    "                + -2*img[y+1, x] + -1*img[y+1, x+1]\n",
    "                \n",
    "                img_[y,x] = (np.abs(H) + np.abs(V))/2\n",
    "            except:\n",
    "                pass\n",
    "    return img_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:44:58.898904Z",
     "start_time": "2021-04-23T12:44:29.934467Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"./images/lena.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img_ = sovel_filter(img)\n",
    "\n",
    "cv2.imshow(\"sovel\", img_)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로버츠 교차 필터\n",
    "- 기본 미분 커널을 개선한 커널로 대각선 방향으로 1과 -1을 배치\n",
    "- 엣지 강도가 약한 단점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:45:07.610226Z",
     "start_time": "2021-04-23T12:45:03.336056Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/lena.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#로버츠 커널 생성\n",
    "gx_kernel = np.array([[1,0], [0,-1]])\n",
    "gy_kernel = np.array([[0,1], [-1,0]])\n",
    "\n",
    "#커널 적용\n",
    "edge_gx = cv2.filter2D(img, -1, gx_kernel)\n",
    "edge_gy = cv2.filter2D(img, -1, gy_kernel)\n",
    "\n",
    "#결과 출력\n",
    "merged = np.c_[img, edge_gx, edge_gy, edge_gx+edge_gy]\n",
    "cv2.imshow('robert', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  샤르 필터\n",
    "- 소벨 필터는 커널의 크기가 작은 경우 엣지 방향성의 정확도가 떨어지는 단점이 있어서 이를 개선한 필터이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:45:21.171183Z",
     "start_time": "2021-04-23T12:45:14.597139Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/lena.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 샤르 커널을 직접 생성해서 엣지 검출 ---①\n",
    "gx_k = np.array([[-3,0,3], [-10,0,10],[-3,0,3]])\n",
    "gy_k = np.array([[-3,-10,-3],[0,0,0], [3,10,3]])\n",
    "edge_gx = cv2.filter2D(img, -1, gx_k)\n",
    "edge_gy = cv2.filter2D(img, -1, gy_k)\n",
    "\n",
    "# 샤르 API로 엣지 검출 ---②\n",
    "scharrx = cv2.Scharr(img, -1, 1, 0)\n",
    "scharry = cv2.Scharr(img, -1, 0, 1)\n",
    "\n",
    "# 결과 출력\n",
    "merged1 = np.hstack((img, edge_gx, edge_gy))\n",
    "merged2 = np.hstack((img, scharrx, scharry))\n",
    "merged = np.vstack((merged1, merged2))\n",
    "cv2.imshow('Scharr', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 라플라시안 필터 \n",
    "- 2차 미분을 적용하면 경계를 좀 더 확실히 검출할 수 있음\n",
    "- 2차 미분 마스크 (cv2.Laplacian())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:45:27.298265Z",
     "start_time": "2021-04-23T12:45:27.231301Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/lena.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 원본 영상을 가우시안 피라미드로 축소\n",
    "smaller = cv2.pyrDown(img)\n",
    "# 축소한 영상을 가우시안 피라미드로 확대\n",
    "bigger = cv2.pyrUp(smaller)\n",
    "\n",
    "# 원본에서 확대한 영상 빼기\n",
    "laplacian = cv2.subtract(img, bigger)\n",
    "# 확대 한 영상에 라플라시안 영상 더해서 복원\n",
    "restored = bigger + laplacian\n",
    "\n",
    "# 결과 출력 (원본 영상, 라플라시안, 확대 영상, 복원 영상)\n",
    "merged = np.hstack((img, laplacian, bigger, restored))\n",
    "cv2.imshow('Laplacian Pyramid', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:45:46.077097Z",
     "start_time": "2021-04-23T12:45:46.033917Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/lena.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (700,700))\n",
    "\n",
    "# 라플라시안 필터 적용 ---①\n",
    "edge = cv2.Laplacian(img, -1)\n",
    "\n",
    "# 결과 출력\n",
    "merged = np.hstack((img, edge))\n",
    "cv2.imshow('Laplacian', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 캐니 엣지 알고리즘\n",
    "1. 노이즈 제거: 5x5 가우시안 블러링 필터 적용\n",
    "2. 엣지 검출: 소벨과 그레디언트로 윤곽석 검출\n",
    "3. 비 최대치 억제: 그레디언트 방향에서 검출된 엣지 중 가증 큰값만 선택\n",
    "4. 이력 스레스홀딩: 두개의 결계값(Max, Min)을 지정해서 경계영역에 있는 화소들 중 Max밖의 픽셀과 연결성이 없는 화소를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:45:59.619386Z",
     "start_time": "2021-04-23T12:45:59.542972Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2, time\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/lena.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (800,800))\n",
    "\n",
    "# 케니 엣지 적용 \n",
    "edges = cv2.Canny(img,100,220)\n",
    "\n",
    "# 결과 출력\n",
    "merged = np.c_[img, edges]\n",
    "cv2.imshow('Canny', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 케니 엣지와 카메라 (p249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:46:39.696005Z",
     "start_time": "2021-04-23T12:46:13.761642Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 카메라 장치 연결\n",
    "cap = cv2.VideoCapture(0)   \n",
    "while cap.isOpened():\n",
    "    # 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "    # 속도 향상을 위해 영상크기를 절반으로 축소\n",
    "    frame = cv2.resize(frame, None, fx=0.7, fy=0.7, \n",
    "                        interpolation=cv2.INTER_AREA)\n",
    "    if cv2.waitKey(1) == 27: # esc키로 종료\n",
    "        break\n",
    "        \n",
    "#   dst = cv2.stylization(fname, sigma_s=100, sigma_r=0.1)\n",
    "# 로 하면 한번에 아래와 같이 만들어짐\n",
    "    # 그레이 스케일로 변경    \n",
    "    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # 잡음 제거를 위해 가우시안 플러 필터 적용(라플라시안 필터 적용 전에 필수)\n",
    "    img_gray = cv2.GaussianBlur(img_gray, (9,9), 0)\n",
    "    # 라플라시안 필터로 엣지 거출\n",
    "    edges = cv2.Laplacian(img_gray, -1, ksize=5)\n",
    "    # 스레시홀드로 경계 값 만 남기고 제거하면서 화면 반전(흰 바탕 검은 선)\n",
    "    ret, sketch = cv2.threshold(edges, 70, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # 경계선 강조를 위해 팽창 연산\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "#     kernel = np.ones((3,3), np.uint8)\n",
    "    sketch = cv2.erode(sketch, kernel)\n",
    "    # 경계선 자연스럽게 하기 위해 미디언 블러 필터 적용\n",
    "    sketch = cv2.medianBlur(sketch, 5)\n",
    "    # 그레이 스케일에서 BGR 컬러 스케일로 변경\n",
    "    img_sketch = cv2.cvtColor(sketch, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 컬러 이미지 선명선을 없애기 위해 평균 블러 필터 적용\n",
    "    img_paint = cv2.blur(frame, (10,10) )\n",
    "    # 컬러 영상과 스케치 영상과 합성\n",
    "    img_paint = cv2.bitwise_and(img_paint, img_paint, mask=sketch)\n",
    "    \n",
    "    # 결과 출력\n",
    "    merged = np.hstack((img_sketch, img_paint))\n",
    "    cv2.imshow('Sketch Camera', merged)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:46:48.361405Z",
     "start_time": "2021-04-23T12:46:39.726413Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 카메라 장치 연결\n",
    "cap = cv2.VideoCapture(0)   \n",
    "while cap.isOpened():\n",
    "    # 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "    # 속도 향상을 위해 영상크기를 절반으로 축소\n",
    "    frame = cv2.resize(frame, None, fx=0.7, fy=0.7, \\\n",
    "                        interpolation=cv2.INTER_AREA)\n",
    "    if cv2.waitKey(1) == 27: # esc키로 종료\n",
    "        break\n",
    "        \n",
    "    dst = cv2.stylization(frame, sigma_s=100, sigma_r=0.1)\n",
    "\n",
    "    cv2.imshow('Sketch Camera', dst)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:47:02.966376Z",
     "start_time": "2021-04-23T12:46:48.389712Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 카메라 장치 연결\n",
    "cap = cv2.VideoCapture(0)   \n",
    "while cap.isOpened():\n",
    "    # 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "    # 속도 향상을 위해 영상크기를 절반으로 축소\n",
    "    frame = cv2.resize(frame, None, fx=0.7, fy=0.7, \\\n",
    "                        interpolation=cv2.INTER_AREA)\n",
    "    if cv2.waitKey(1) == 27: # esc키로 종료\n",
    "        break\n",
    "        \n",
    "#     dst = cv2.edgePreservingFilter(frame, flags =1, sigma_s=60, sigma_r=0.2)\n",
    "#     dst = cv2.detailEnhance(frame, sigma_s=60, sigma_r=0.2)\n",
    "#     dst = np.hstack((frame, dst))\n",
    "\n",
    "    dst_gray, dst_color = cv2.pencilSketch(frame, sigma_s=80, sigma_r=0.1, shade_factor=0.05)\n",
    "    dst_gray = cv2.cvtColor(dst_gray, cv2.COLOR_GRAY2BGR)\n",
    "    dst = np.hstack((dst_gray, dst_color))\n",
    "\n",
    "    cv2.imshow('Sketch Camera', dst)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손글씨 숫자 인식하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:34:13.918251Z",
     "start_time": "2021-04-26T06:34:13.886279Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/digits.png', cv2.IMREAD_GRAYSCALE)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:34:14.783307Z",
     "start_time": "2021-04-26T06:34:14.755323Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cells = [np.hsplit(row, 100) for row in np.vsplit(img, 50)]\n",
    "x=np.array(cells)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:34:45.921505Z",
     "start_time": "2021-04-26T06:34:41.086855Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = x[:,:].reshape(-1, 400).astype(np.float32)  #머신러닝은 무조건 1차원으로 딥러닝은 2차원으로\n",
    "y = np.repeat(np.arange(10), 500)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (512, 256, 128), verbose=True)\n",
    "\n",
    "mlp.fit(train_X, train_y)\n",
    "\n",
    "#랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "print(mlp.score(test_X, test_y))\n",
    "print(rf_model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:59:53.041807Z",
     "start_time": "2021-04-23T12:59:44.314517Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img4 = cv2.imread('./images/four.png', 0)\n",
    "cv2.imshow('4', img4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:59:58.601594Z",
     "start_time": "2021-04-23T12:59:58.595377Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "number = img4.reshape(-1, 400)\n",
    "print(mlp.predict_proba(number))\n",
    "print(np.argmax(mlp.predict_proba(number)))\n",
    "print(mlp.predict(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:00:04.149776Z",
     "start_time": "2021-04-23T13:00:04.134016Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./model/number.model\", 'wb') as f:\n",
    "    pickle.dump(mlp, f)\n",
    "    \n",
    "with open(\"./model/number_rf.model\", 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "import pickle\n",
    "with open(\"./model/number.model\", 'rb') as f:\n",
    "    mlp2 = pickle.load(f)\n",
    "    \n",
    "print(mlp2.predict_proba(number))\n",
    "print(mlp2.predict(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T13:00:38.175214Z",
     "start_time": "2021-04-23T13:00:09.529402Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./model/number.model\", \"rb\") as f:\n",
    "    mlp2 = pickle.load(f)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            g_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            _, bin_img = cv2.threshold(g_img, 110, 255, cv2.THRESH_BINARY_INV)\n",
    "            contours, hierarchy = cv2.findContours(bin_img, \n",
    "                        cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # CHAIN_APPROX_SIMPLE 테두리를 잡아줌 \n",
    "            try:\n",
    "                for i in range(len(contours)):\n",
    "                    contour = contours[i]\n",
    "                    (x,y), radius = cv2.minEnclosingCircle(contour)\n",
    "                    if radius > 3:\n",
    "                        xs, xe = int(x-radius), int(x+radius)\n",
    "                        ys, ye = int(y-radius), int(y+radius)\n",
    "                        cv2.rectangle(bin_img, (xs, ys), (xe, ye), (200, 0, 0), 1)\n",
    "                        roi = bin_img[ys:ye, xs:xe]\n",
    "                        dst = cv2.resize(roi, dsize = (50, 50), \n",
    "                                         interpolation = cv2.INTER_AREA)\n",
    "                        dst = cv2.resize(dst, dsize = (16, 16),\n",
    "                                        interpolation = cv2.INTER_AREA)\n",
    "                        A = np.zeros((20,20))\n",
    "                        A[2:-2, 2:-2] = dst[:,:]\n",
    "                        A = A.reshape(-1,400)\n",
    "                        num = mlp2.predict(A)\n",
    "                        cv2.putText(bin_img, str(num), (xs,ys), cv2.FONT_HERSHEY_PLAIN, 2, (200, 0, 0))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            cv2.imshow(\"Image\", bin_img)\n",
    "            if cv2.waitKey(1) & 0xFF ==27:\n",
    "                break\n",
    "        else:\n",
    "            print(\"Np Frame\")\n",
    "            break\n",
    "else:\n",
    "    print(\"Camera not opened\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6장 특징 추출\n",
    "### 컨투어 계층 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:51:08.404963Z",
     "start_time": "2021-04-23T12:50:59.856578Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 영상 읽기\n",
    "img = cv2.imread('./images/shape.png')\n",
    "img2 = img.copy()\n",
    "# 바이너리 이미지로 변환\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, imthres = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "print(imthres)\n",
    "# 가장 바깥 컨투어만 수집   --- ①\n",
    "contour, hierarchy = cv2.findContours(imthres, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "# 컨투어 갯수와 계층 트리 출력 --- ②\n",
    "print(len(contour), hierarchy)\n",
    "\n",
    "# 모든 컨투어를 트리 계층 으로 수집 ---③\n",
    "contour2, hierarchy = cv2.findContours(imthres, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# 컨투어 갯수와 계층 트리 출력 ---④\n",
    "print(len(contour2), hierarchy)\n",
    "\n",
    "# 가장 바깥 컨투어만 그리기 ---⑤\n",
    "cv2.drawContours(img, contour, -1, (0,255,0), 3)\n",
    "# 모든 컨투어 그리기 ---⑥\n",
    "for idx, cont in enumerate(contour2): \n",
    "    # 랜덤한 컬러 추출 ---⑦\n",
    "    color = [int(i) for i in np.random.randint(0,255, 3)]\n",
    "    # 컨투어 인덱스 마다 랜덤한 색상으로 그리기 ---⑧\n",
    "    cv2.drawContours(img2, contour2, idx, color, 3)\n",
    "    # 컨투어 첫 좌표에 인덱스 숫자 표시 ---⑨\n",
    "    cv2.putText(img2, str(idx), tuple(cont[0][0]), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255))\n",
    "\n",
    "# 화면 출력\n",
    "cv2.imshow('RETR_EXTERNAL', img)\n",
    "cv2.imshow('RETR_TREE', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  모멘트를 이용한 중심점, 넓이, 둘레길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:51:58.005757Z",
     "start_time": "2021-04-23T12:51:13.685478Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/shape.png')\n",
    "# 그레이 스케일 변환\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# 바이너리 스케일 변환\n",
    "ret, th = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "# 컨투어 찾기\n",
    "contours, hierachy = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# 각 도형의 컨투어에 대한 루프\n",
    "for c in contours:\n",
    "    # 모멘트 계산\n",
    "    mmt = cv2.moments(c)\n",
    "    # m10/m00, m01/m00  중심점 계산\n",
    "    cx = int(mmt['m10']/mmt['m00'])\n",
    "    cy = int(mmt['m01']/mmt['m00'])\n",
    "    # 영역 넓이\n",
    "    a = mmt['m00']\n",
    "    # 영역 외곽선 길이\n",
    "    l = cv2.arcLength(c, True)\n",
    "    # 중심점에 노란색 점 그리기\n",
    "    cv2.circle(img, (cx, cy), 5, (0, 255, 255), -1)\n",
    "    # 중심점 근처에 넓이 그리기\n",
    "    cv2.putText(img, \"A:%.0f\"%a, (cx, cy+20) , cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255))\n",
    "    # 컨투어 시작점에 길이 그리기\n",
    "    cv2.putText(img, \"L:%.2f\"%l, tuple(c[0][0]), cv2.FONT_HERSHEY_PLAIN, 1, (255,0,0))\n",
    "    # 함수로 컨투어 넓이 계산해서 출력\n",
    "    print(\"area:%.2f\"%cv2.contourArea(c, False))\n",
    "\n",
    "# 결과 출력\n",
    "cv2.imshow('center', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨투어를 감싸는 그림 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:52:46.057883Z",
     "start_time": "2021-04-23T12:52:33.457149Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 이미지 읽어서 그레이스케일 변환, 바이너리 스케일 변환\n",
    "img = cv2.imread(\"./images/lightning.png\")\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, th = cv2.threshold(imgray, 127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# 컨튜어 찾기\n",
    "contours, hr = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contr = contours[0]\n",
    "\n",
    "# 감싸는 사각형 표시(검정색)\n",
    "x,y,w,h = cv2.boundingRect(contr)\n",
    "cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,0), 3)\n",
    "\n",
    "# 최소한의 사각형 표시(초록색)\n",
    "rect = cv2.minAreaRect(contr)\n",
    "box = cv2.boxPoints(rect)   # 중심점과 각도를 4개의 꼭지점 좌표로 변환\n",
    "box = np.int0(box)          # 정수로 변환\n",
    "cv2.drawContours(img, [box], -1, (0,255,0), 3)\n",
    "\n",
    "# 최소한의 원 표시(파랑색)\n",
    "(x,y), radius = cv2.minEnclosingCircle(contr)\n",
    "cv2.circle(img, (int(x), int(y)), int(radius), (255,0,0), 2)\n",
    "\n",
    "# 최소한의 삼각형 표시(분홍색)\n",
    "ret, tri = cv2.minEnclosingTriangle(contr)\n",
    "cv2.polylines(img, [np.int32(tri)], True, (255,0,255), 2)\n",
    "\n",
    "# 최소한의 타원 표시(노랑색)\n",
    "ellipse = cv2.fitEllipse(contr)\n",
    "cv2.ellipse(img, ellipse, (0,255,255), 3)\n",
    "\n",
    "# 중심점 통과하는 직선 표시(빨강색)\n",
    "[vx,vy,x,y] = cv2.fitLine(contr, cv2.DIST_L2,0,0.01,0.01)\n",
    "cols,rows = img.shape[:2]\n",
    "\n",
    "cv2.line(img,(0, int(0-x*(vy/vx) + y)), (cols-1, int((cols-x)*(vy/vx) + y)), (0,0,255),2)\n",
    "\n",
    "# lefty = int((-x * vy / vx) + y)\n",
    "# righty = int(((img.shape[1] - x) * vy / vx) + y)  # Finally draw the line\n",
    "# cv2.line(img, (img.shape[1] - 1, righty), (0, lefty), 255, 2)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "cv2.imshow('Bound Fit shapes', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 근사 컨투어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:54:16.560820Z",
     "start_time": "2021-04-23T12:52:46.130851Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/bad_rect.png')\n",
    "img2 = img.copy()\n",
    "\n",
    "# 그레이스케일과 바이너리 스케일 변환\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "ret, th = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# 컨투어 찾기 ---①\n",
    "contours, hierachy = cv2.findContours(th, cv2.RETR_EXTERNAL, \\\n",
    "                                     cv2.CHAIN_APPROX_SIMPLE)\n",
    "contour = contours[0]\n",
    "# 전체 둘레의 0.05로 오차 범위 지정 ---②\n",
    "epsilon = 0.05 * cv2.arcLength(contour, True)\n",
    "# 근사 컨투어 계산 ---③\n",
    "approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "# 각각 컨투어 선 그리기 ---④\n",
    "cv2.drawContours(img, [contour], -1, (0,255,0), 3)\n",
    "cv2.drawContours(img2, [approx], -1, (0,255,0), 3)\n",
    "\n",
    "# 결과 출력\n",
    "cv2.imshow('contour', img)\n",
    "cv2.imshow('approx', img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T12:55:01.495546Z",
     "start_time": "2021-04-23T12:54:25.936263Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/hand.jpg')\n",
    "img2 = img.copy()\n",
    "# 그레이 스케일 및 바이너리 스케일 변환 ---①\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# 컨투어 찾기와 그리기 ---②\n",
    "contours, heiarchy = cv2.findContours(th, cv2.RETR_EXTERNAL, \\\n",
    "                                         cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cntr = contours[0]\n",
    "cv2.drawContours(img, [cntr], -1, (0, 255,0), 1)\n",
    "\n",
    "# 볼록 선체 찾기(좌표 기준)와 그리기 ---③\n",
    "hull = cv2.convexHull(cntr)\n",
    "cv2.drawContours(img2, [hull], -1, (0,255,0), 1)\n",
    "# 볼록 선체 만족 여부 확인 ---④\n",
    "print(cv2.isContourConvex(cntr), cv2.isContourConvex(hull))\n",
    "\n",
    "# 볼록 선체 찾기(인덱스 기준) ---⑤\n",
    "hull2 = cv2.convexHull(cntr, returnPoints=False)\n",
    "# 볼록 선체 결함 찾기 ---⑥\n",
    "defects = cv2.convexityDefects(cntr, hull2)\n",
    "# 볼록 선체 결함 순회\n",
    "for i in range(defects.shape[0]):\n",
    "    # 시작, 종료, 가장 먼 지점, 거리 ---⑦\n",
    "    startP, endP, farthestP, distance = defects[i, 0]\n",
    "    # 가장 먼 지점의 좌표 구하기 ---⑧\n",
    "    farthest = tuple(cntr[farthestP][0])\n",
    "    # 거리를 부동 소수점으로 변환 ---⑨\n",
    "    dist = distance/256.0\n",
    "    # 거리가 1보다 큰 경우 ---⑩\n",
    "    if dist > 1 :\n",
    "        # 빨강색 점 표시 \n",
    "        cv2.circle(img2, farthest, 3, (0,0,255), -1)\n",
    "# 결과 이미지 표시\n",
    "cv2.imshow('contour', img)\n",
    "cv2.imshow('convex hull', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## 캐스케이드 분류기\n",
    " - p420\n",
    " ### 하르 캐스케이드 얼굴 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:18:38.984767Z",
     "start_time": "2021-04-26T02:18:36.822539Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 얼굴 검출을 위한 케스케이드 분류기 생성 --- ①\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade/haarcascade_frontalface_default.xml')\n",
    "# 눈 검출을 위한 케스케이드 분류기 생성 ---②\n",
    "eye_cascade = cv2.CascadeClassifier('./haarcascade/haarcascade_eye.xml')\n",
    "# 검출할 이미지 읽고 그레이 스케일로 변환 ---③\n",
    "img = cv2.imread('./images/lena.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# 얼굴 검출 ---④\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "# 검출된 얼굴 순회 ---⑤\n",
    "for (x,y,w,h) in faces:\n",
    "    # 검출된 얼굴에 사각형 표시 ---⑥\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    # 얼굴 영역을 ROI로 설정 ---⑦\n",
    "    roi = gray[y:y+h, x:x+w]\n",
    "    # ROI에서 눈 검출 ---⑧\n",
    "    eyes = eye_cascade.detectMultiScale(roi)\n",
    "    # 검출된 눈에 사각형 표 ---⑨\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(img[y:y+h, x:x+w],(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "# 결과 출력 \n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카메라로 얼굴, 눈과 입 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:59:43.264482Z",
     "start_time": "2021-04-26T02:58:08.906423Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./haarcascade/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('./haarcascade/haarcascade_smile.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read() #프레임 읽기\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #얼굴 검출\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(80,80))\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(img, \"Face\", (x,y), cv2.FONT_ITALIC, 1, (0, 255, 0))\n",
    "            roi = gray[y:y+h, x:x+w]\n",
    "            \n",
    "            #눈 검출\n",
    "            eyes = eye_cascade.detectMultiScale(roi)\n",
    "            for i, (ex, ey, ew, eh) in enumerate(eyes):\n",
    "                if i>=2:\n",
    "                    break\n",
    "                cv2.rectangle(img[y:y+h, x:x+w], (ex, ey), (ex+ew, ey+eh), (255,0,0), 2)\n",
    "            \n",
    "            #입 검출\n",
    "            lips = smile_cascade.detectMultiScale(roi)\n",
    "            for i, (lx, ly, lw, lh) in enumerate(lips):\n",
    "                if i >2:\n",
    "                    break\n",
    "                cv2.rectangle(img[y:y+h, x:x+w], (lx, ly), (lx+lw, ly+lh), (0,0,255), 2)\n",
    "        cv2.imshow('face detect', img)\n",
    "    else: \n",
    "        break\n",
    "    if cv2.waitKey(5) == 27:\n",
    "        break\n",
    "    elif cv2.waitKey(5) == ord('c'):\n",
    "        captured = True\n",
    "        break\n",
    "\n",
    "if captured:\n",
    "    cap.release()\n",
    "    while True:\n",
    "        cv2.imshow('Capture', img)\n",
    "        key = cv2.waitKey(0)\n",
    "        if key & 0xFF ==27:\n",
    "            break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 인식 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:21:31.873050Z",
     "start_time": "2021-04-26T05:20:11.056264Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# 변수 설정 ---①\n",
    "base_dir = './faces/'   # 사진 저장할 디렉토리 경로\n",
    "target_cnt = 400        # 수집할 사진 갯수\n",
    "cnt = 0                 # 사진 촬영 수\n",
    "\n",
    "# 얼굴 검출 분류기 생성 --- ②\n",
    "face_classifier = cv2.CascadeClassifier(\\\n",
    "                    './haarcascade/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 사용자 이름과 번호를 입력 받아 디렉토리 생성 ---③\n",
    "name = input(\"Insert User Name(Only Alphabet):\")\n",
    "id = input(\"Insert User Id(Non-Duplicate number):\")\n",
    "dir = os.path.join(base_dir, name+'_'+ id)\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "# 카메라 캡쳐 \n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read(5)\n",
    "    if ret:\n",
    "        img = frame.copy()\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # 얼굴 검출 --- ④\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "        if len(faces) == 1:\n",
    "            (x,y,w,h) = faces[0]\n",
    "            # 얼굴 영역 표시 및 파일 저장 ---⑤\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 1)\n",
    "            face = gray[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, (200, 200))\n",
    "            file_name_path = os.path.join(dir,  str(cnt) + '.jpg')\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(frame, str(cnt), (x, y), cv2.FONT_HERSHEY_COMPLEX, \\\n",
    "                             1, (0,255,0), 2)\n",
    "            cnt+=1\n",
    "        else:\n",
    "            # 얼굴 검출이 없거나 1이상 인 경우 오류 표시 ---⑥\n",
    "            if len(faces) == 0 :\n",
    "                msg = \"no face.\"\n",
    "            elif len(faces) > 1:\n",
    "                msg = \"too many face.\"\n",
    "            cv2.putText(frame, msg, (10, 50), cv2.FONT_HERSHEY_DUPLEX, \\\n",
    "                            1, (0,0,255))\n",
    "        cv2.imshow('face record', frame)\n",
    "        if cv2.waitKey(1) == 27 or cnt == target_cnt: \n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:21:58.170993Z",
     "start_time": "2021-04-26T05:21:35.255923Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "# 변수 설정 --- ①\n",
    "base_dir = './faces'\n",
    "train_data, train_labels = [], []\n",
    "\n",
    "\n",
    "dirs = [d for d in glob.glob(base_dir+\"/*\") if os.path.isdir(d)]\n",
    "print('Collecting train data set:')\n",
    "for dir in dirs:\n",
    "    # name_id 형식에서 id를 분리 ---②\n",
    "    id = dir.split('_')[1]          \n",
    "    files = glob.glob(dir+'/*.jpg')\n",
    "    print('\\t path:%s, %dfiles'%(dir, len(files)))\n",
    "    for file in files:\n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        # 이미지는 train_data, 아이디는 train_lables에 저장 ---③\n",
    "        train_data.append(np.asarray(img, dtype=np.uint8))\n",
    "        train_labels.append(int(id))\n",
    "\n",
    "# NumPy 배열로 변환 ---④\n",
    "train_data = np.asarray(train_data)\n",
    "train_labels = np.int32(train_labels)\n",
    "\n",
    "# LBP 얼굴인식기 생성 및 훈련 ---⑤\n",
    "print('Starting LBP Model training...')\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(train_data, train_labels)\n",
    "model.write('./faces/all_face.xml')\n",
    "print(\"Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:23:26.755374Z",
     "start_time": "2021-04-26T05:22:00.800767Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "# 변수 설정 ---①\n",
    "base_dir = './faces'\n",
    "min_accuracy = 85\n",
    "\n",
    "# LBP 얼굴 인식기 및 케스케이드 얼굴 검출기 생성 및 훈련 모델 읽기 ---②\n",
    "face_classifier = cv2.CascadeClassifier(\\\n",
    "                './haarcascade/haarcascade_frontalface_default.xml')\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.read(os.path.join(base_dir, 'all_face.xml'))\n",
    "\n",
    "# 디렉토리 이름으로 사용자 이름과 아이디 매핑 정보 생성 ---③\n",
    "dirs = [d for d in glob.glob(base_dir+\"/*\") if os.path.isdir(d)]\n",
    "names = dict([])\n",
    "for dir in dirs:\n",
    "    dir = os.path.basename(dir)\n",
    "    name, id = dir.split('_')\n",
    "    names[int(id)] = name\n",
    "\n",
    "# 카메라 캡처 장치 준비 \n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"no frame\")\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    # 얼굴 검출 ---④\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        # 얼굴 영역 표시하고 샘플과 같은 크기로 축소 ---⑤\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # LBP 얼굴 인식기로 예측 ---⑥\n",
    "        label, confidence = model.predict(face)\n",
    "        if confidence < 400:\n",
    "            # 정확도 거리를 퍼센트로 변환 ---⑦\n",
    "            accuracy = int( 100 * (1 -confidence/400))\n",
    "            if accuracy >= min_accuracy:\n",
    "                msg =  '%s(%.0f%%)'%(names[label], accuracy)\n",
    "            else:\n",
    "                msg = 'Unknown'\n",
    "        # 사용자 이름과 정확도 결과 출력 ---⑧\n",
    "        txt, base = cv2.getTextSize(msg, cv2.FONT_HERSHEY_PLAIN, 1, 3)\n",
    "        cv2.rectangle(frame, (x,y-base-txt[1]), (x+txt[0], y+txt[1]), \\\n",
    "                    (0,255,255), -1)\n",
    "        cv2.putText(frame, msg, (x, y), cv2.FONT_HERSHEY_PLAIN, 1, \\\n",
    "                    (200,200,200), 2,cv2.LINE_AA)\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "    if cv2.waitKey(1) == 27: #esc \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 해리스 코너 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:53:50.619544Z",
     "start_time": "2021-04-26T06:53:46.198204Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./images/house.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "corner = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "\n",
    "coord = np.where(corner > 0.3 * corner.max())\n",
    "coord = np.stack((coord[1], coord[0]), axis=-1)\n",
    "\n",
    "#코너 좌표에 동그라미 그리기\n",
    "for x, y in coord:\n",
    "    cv2.circle(img, (x,y), 5, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "#변화량을 영상으로 표현하기 위해서 0~255 로 정규화\n",
    "corner_norm = cv2.normalize(corner, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "\n",
    "#화면에 출력\n",
    "corner_norm = cv2.cvtColor(corner_norm, cv2.COLOR_GRAY2BGR)\n",
    "merged = np.hstack((corner_norm, img))\n",
    "cv2.imshow('Harris', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracker APIs \n",
    "- 트랙커에 초기 추적 대상 객체의 위치르 ㄹ알려주고 update()함수에 다름 프레임을 전달하면 객체가 이동한 위치를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-26T07:04:13.797Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "# 트랙커 객체 생성자 함수 리스트 ---①\n",
    "trackers = [cv2.TrackerBoosting_create,\n",
    "            cv2.TrackerMIL_create,\n",
    "            cv2.TrackerKCF_create,\n",
    "            cv2.TrackerTLD_create,\n",
    "            cv2.TrackerMedianFlow_create,\n",
    "            cv2.TrackerGOTURN_create, #버그로 오류 발생\n",
    "            cv2.TrackerCSRT_create,\n",
    "            cv2.TrackerMOSSE_create]\n",
    "trackerIdx = 0  # 트랙커 생성자 함수 선택 인덱스\n",
    "tracker = None\n",
    "isFirst = True\n",
    "\n",
    "video_src = 0 # 비디오 파일과 카메라 선택 ---②\n",
    "# video_src = \"./images/highway.mp4\"\n",
    "cap = cv2.VideoCapture(video_src)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "win_name = 'Tracking APIs'\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('Cannot read video file')\n",
    "        break\n",
    "    img_draw = frame.copy()\n",
    "    if tracker is None: # 트랙커 생성 안된 경우\n",
    "        cv2.putText(img_draw, \"Press the Space to set ROI!!\", \\\n",
    "            (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2,cv2.LINE_AA)\n",
    "    else:\n",
    "        ok, bbox = tracker.update(frame)   # 새로운 프레임에서 추적 위치 찾기 ---③\n",
    "        (x,y,w,h) = bbox\n",
    "        if ok: # 추적 성공\n",
    "            cv2.rectangle(img_draw, (int(x), int(y)), (int(x + w), int(y + h)), \\\n",
    "                          (0,255,0), 2, 1)\n",
    "        else : # 추적 실패\n",
    "            cv2.putText(img_draw, \"Tracking fail.\", (100,80), \\\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2,cv2.LINE_AA)\n",
    "    trackerName = tracker.__class__.__name__\n",
    "    cv2.putText(img_draw, str(trackerIdx) + \":\"+trackerName , (100,20), \\\n",
    "                 cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0),2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(win_name, img_draw)\n",
    "    key = cv2.waitKey(delay) & 0xff\n",
    "    # 스페이스 바 또는 비디오 파일 최초 실행 ---④\n",
    "    if key == ord(' ') or (video_src != 0 and isFirst): \n",
    "        isFirst = False\n",
    "        roi = cv2.selectROI(win_name, frame, False)  # 초기 객체 위치 설정\n",
    "        if roi[2] and roi[3]:         # 위치 설정 값 있는 경우\n",
    "            tracker = trackers[trackerIdx]()    #트랙커 객체 생성 ---⑤\n",
    "            isInit = tracker.init(frame, roi)\n",
    "    elif key in range(48, 56): # 0~7 숫자 입력   ---⑥\n",
    "        trackerIdx = key-48     # 선택한 숫자로 트랙커 인덱스 수정\n",
    "        if bbox is not None:\n",
    "            tracker = trackers[trackerIdx]() # 선택한 숫자의 트랙커 객체 생성 ---⑦\n",
    "            isInit = tracker.init(frame, bbox) # 이전 추적 위치로 추적 위치 초기화\n",
    "    elif key == 27 : \n",
    "        break\n",
    "else:\n",
    "    print( \"Could not open video\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260.833px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "290.99px",
    "left": "848.479px",
    "right": "20px",
    "top": "193.993px",
    "width": "447.483px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}